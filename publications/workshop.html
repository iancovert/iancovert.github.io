<p>
  <a href="https://arxiv.org/abs/2106.06654">Disrupting Model Training With Adversarial Shortcuts</a>
  <br>
  Ivan Evtimov, <strong>Ian Covert</strong>, Aditya Kusupati, Tadayoshi Kohno
  <br>
  <em>In the Adversarial ML Workshop at ICML 2021</em>
</p>

<p>
  <a href="https://arxiv.org/abs/2011.03623">Feature Removal Is a Unifying Principle for Model Explanation Methods</a>
  <br>
  <strong>Ian Covert</strong>, Scott Lundberg, Su-In Lee
  <br>
  <em>In the Machine Learning Retrospectives & Meta-Analyses (ML-RSA) Workshop at NeurIPS 2020</em>
</p>

<p>
  <a href="https://iancovert.com/publications/Shapley_Feature_Utility_MLCB_2019.pdf">Shapley Feature Utility</a>
  <br>
  <strong>Ian Covert</strong>, Scott Lundberg, Su-In Lee
  <br>
  <em>In Machine Learning for Computational Biology (MLCB 2019)</em>
</p>

<p>
  <a href="https://iancovert.com/publications/Principal_Genes_MLCB_2019.pdf">Principal Genes Selection</a>
  <br>
  <strong>Ian Covert</strong>, Uygar S&uuml;mb&uuml;l, Su-In Lee
  <br>
  <em>In Machine Learning for Computational Biology (MLCB 2019)</em>
</p>

<p>
  <a href="javascript:;">EEG Seizure Detection via Deep Neural Networks: Application and Interpretation</a>
  <br>
  Jiening Zhan, Hector Yee, <strong>Ian Covert</strong>, Jiang Wu, Albee Ling, Matthew Shore, Eric Teasley, Rebecca Davies, Tiffany Kung, Justin Tansuwan, John Hixson and Ming Jack Po
  <br>
  <em>In the Machine Learning for Healthcare (ML4H) Workshop at NeurIPS 2019</em>
</p>

<p>
  <a href="https://arxiv.org/abs/1711.08160">An Interpretable and Sparse Neural Network Model for Nonlinear Granger Causality Discovery</a>
  <br>
  Alex Tank, <strong>Ian Covert</strong>, Nicholas Foti, Ali Shojaie, Emily Fox
  <br>
  <em>In the Time Series Workshop (TSW) at NeurIPS 2017</em>
</p>